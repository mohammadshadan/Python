ggplot(mtcars, aes(wt,mpg)) + geom_point() + facet_grid(2~cyl)
ggplot(mtcars, aes(wt,mpg)) + geom_point() + facet_grid(.~cyl)
ggplot(mtcars, aes(wt,mpg)) + geom_point() + facet_wrap(cyl~,ncol=2)
ggplot(mtcars, aes(wt,mpg)) + geom_point() + facet_wrap(~cyl,ncol=1)
g + geom_point(alpha=1/3) + facet_wrap(~class, ncol=1)
head(mtcars)
mtcars[1:10]
mtcars[1:10,]
mtcars[1:10,c(1:3,5)]
data("airquality")
data(airquality)
a <- airquality
head(a)
table(is.na(a))
summary(a)
names(a)[colSums(a)>0]
names(a)[colSums(is.na(a))>0]
table(is.na(a$Ozone))
mean(a$Ozone)
mean(a$Ozone, na.rm = True)
mean(a$Ozone, na.rm = TRUE)
a$Ozone <- ifelse(is.na(a$Ozone), mean(a$Ozone, na.rm = TRUE), a$Ozone)
mean(a$Ozone, na.rm = TRUE)
a$Ozone
head(a)
a[a$Ozone==42.12931,]
a[round(a$Ozone)==42,]
nrow(a[round(a$Ozone)==42,])
head(iris)
barplot(iris$Species)
plot(iris$Species)
library(ggplot2)
ggplot(iris, aes(x=Species)) + geom_bar()
ggplot(iris, aes(x=Species, fill=Species)) + geom_bar()
ggplot(iris, aes(y=Species, fill=Species)) + geom_bar()
ggplot(iris, aes(x=Species, fill=Species)) + geom_bar()
head(iris)
ggplot(iris, aes(x=Sepal.Length)) + geom_line()
ggplot(iris, aes(y=Sepal.Length)) + geom_line()
names(iris)
ggplot(iris, aes(x=Sepal.Length)) + geom_line()
ggplot(iris, aes(y=Sepal.Length)) + geom_line()
plot(iris$Sepal.Length)
library(diamonds)
library(diamond)
data(diamond)
data(diamonds)
str(diamonds)
ggplot(diamonds, aes(x='color')) + geom_bar()
ggplot(diamonds, aes(x=color)) + geom_bar()
ggplot(diamonds, aes(x=color, fill=color)) + geom_bar()
library(auto)
x<- rnorm(10000)
ggplot(NULL, aes(x)) + geom_histogram()
plot(x)
hist(x)
library(dplyr)
library(ggplot2)
library(NHANES)
install.packages("NHANES")
library(NHANES)
names(NHANES)
ggplot(NHANES, aes(x = HomeOwn, fill = Gender)) +
geom_bar(position = "fill") +
ylab("Relative frequencies")
ggplot(NHANES, aes(x = HomeOwn, fill = Gender)) +
geom_bar() +
ylab("Relative frequencies")
# Create bar plot for Home Ownership by Gender
ggplot(NHANES, aes(x = HomeOwn, fill = Gender)) +
geom_bar(position = "fill") +
ylab("Relative frequencies")
ggplot(NHANES, aes(x =  SleepHrsNight, col = SleepTrouble)) +
geom_density(adjust = adjust=2) +
facet_wrap(~ HealthGen)
ggplot(NHANES, aes(x =  SleepHrsNight, col = SleepTrouble)) +
geom_density(adjust = adjust=2) +
facet_wrap(~HealthGen)
ggplot(NHANES, aes(x =  SleepHrsNight, col = SleepTrouble)) +
geom_density(adjust = adjust=2)
ggplot(NHANES, aes(x =  SleepHrsNight, col = SleepTrouble)) +
geom_density(adjust=2) +
facet_wrap(~HealthGen)
ggplot(NHANES, aes(x =  SleepHrsNight, col = SleepTrouble)) +
geom_density(adjust=2) +
facet_wrap(~HealthGen,ncol=3)
ggplot(NHANES, aes(x =  SleepHrsNight, col = SleepTrouble)) +
geom_density(adjust=2) +
facet_wrap(~HealthGen,ncol=4)
ggplot(NHANES, aes(x =  SleepHrsNight, col = SleepTrouble)) +
geom_density(adjust=2) +
facet_wrap(~HealthGen)
ggplot(NHANES, aes(x = Gender, fill = HomeOwn)) +
geom_bar(position = "fill") +
ylab("Relative frequencies")
ggplot(NHANES, aes(x =  SleepHrsNight, col = SleepTrouble)) +
geom_density(adjust=2) +
facet_wrap(~HealthGen)
head(NHANES)
class(NHANES)
homes <- NHANES %>%
select(Gender, HomeOwn) %>%
filter(HomeOwn %in% c("Own", "Rent"))
head(homes)
homes %>%
mutate(HomeOwn_perm = sample(HomeOwn))
homes %>%
mutate(HomeOwn_perm = sample(HomeOwn)) %>%
group_by(Gender) %>%
summarize(prop_own_perm = mean(HomeOwn_perm == "Own"),
prop_own = mean(HomeOwn == "Own")) %>%
homes %>%
mutate(HomeOwn_perm = sample(HomeOwn)) %>%
group_by(Gender) %>%
summarize(prop_own_perm = mean(HomeOwn_perm == "Own"),
prop_own = mean(HomeOwn == "Own"))
summarize(diff_perm = diff(prop_own_perm),
diff_orig = diff(prop_own))
homes %>%
mutate(HomeOwn_perm = sample(HomeOwn)) %>%
group_by(Gender) %>%
summarize(prop_own_perm = mean(HomeOwn_perm == "Own"),
prop_own = mean(HomeOwn == "Own")) %>%
summarize(diff_perm = diff(prop_own_perm),
diff_orig = diff(prop_own))
install.packages("hflights")
library(dplyr)
library(hflights)
head(hflights)
summary(hflights)
dim(hflights)
# Convert the hflights data.frame into a hflights tbl
hflights <- tbl_df(hflights)
# Display the hflights tbl
hflights
# Create the object carriers
carriers <- hflights$UniqueCarrier
str(hflights)
two <- c("AA", "AS")
lut <- c("AA" = "American",
"AS" = "Alaska",
"B6" = "JetBlue")
lut
two <- lut[two]
two
# Both the dplyr and hflights packages are loaded into workspace
lut <- c("AA" = "American", "AS" = "Alaska", "B6" = "JetBlue", "CO" = "Continental",
"DL" = "Delta", "OO" = "SkyWest", "UA" = "United", "US" = "US_Airways",
"WN" = "Southwest", "EV" = "Atlantic_Southeast", "F9" = "Frontier",
"FL" = "AirTran", "MQ" = "American_Eagle", "XE" = "ExpressJet", "YV" = "Mesa")
# Add the Carrier column to hflights
hflights$Carrier <- lut[hflights$UniqueCarrier]
# Glimpse at hflights
glimpse(hflights)
?hflights
library(psych)
bmi_cc <- read.clipboard()
bmi_cc <- read.clipboard(header = TRUE)
bmi_cc <- read.clipboard(header = TRUE)
bmi_cc <- read.delim("clipboard")
bmi_cc <- read.clipboard(header = TRUE)
bmi_cc <- read.delim("clipboard")
bmi_cc
names(bmi_cc)
bmi_cc <- read.delim("clipboard", sep = " ")
bmi_cc <- read.delim("clipboard", sep = " ",header = TRUE)
bmi_cc <- read.delim("clipboard", sep = " ",header = TRUE)
bmi_cc
bmi_cc <- read.delim("clipboard",header = TRUE)
bmi_cc <- read.clipboard(header = TRUE)
bmi_cc <- read.delim("clipboard",header = TRUE)
bmi_cc
library(tidyr)
separate(bmi_cc, Country_ISO..year..bmi_val, c("Country_ISO","year","bmi_val"))
separate(bmi_cc, Country_ISO..year..bmi_val, c("Country_ISO","year","bmi_val"), sep="...")
library(ggplot2)
data(diamonds)
head(diamonds)
str(diamonds)
q()
library (cluster)
library (vegan)
install.packages("vegan")
library (vegan)
data(varespec)
head(varespec)
dis = vegdist(varespec)
res = pam(dis,3) # or whatever your choice of clustering algorithm is
sil = silhouette (res$clustering,dis) # or use your cluster vector
plot(sil)
windows() # RStudio sometimes does not display silhouette plots correctly
plot(sil)
library (vegan)
library (cluster)
data(varespec)
dis = dist(varespec)^2
km <- kmeans(data, centers = 3)
data = iris[,-5]
km <- kmeans(data, centers = 3)
km
wss <- 0
for (i in 1:15) {
km.out <- kmeans(data, centers = i, nstart=20)
# Save total within sum of squares to wss variable
wss[i] <- km.out$tot.withinss
}
plot(1:15, wss, type = "b",
xlab = "Number of Clusters",
ylab = "Within groups sum of squares")
data = mtcars
wss <- 0
for (i in 1:15) {
km.out <- kmeans(data, centers = i, nstart=20)
# Save total within sum of squares to wss variable
wss[i] <- km.out$tot.withinss
}
plot(1:15, wss, type = "b",
xlab = "Number of Clusters",
ylab = "Within groups sum of squares")
head(data)
clip <- read.delim("clipboard")
head(clip)
rownames(clip)
class(clip)
clip <- read.delim("clipboard")
head(clip)
rownames(clip)
class(clip)
x <- read.delim("clipboard")
x
names(x)
hclust.complete <- hclust(dist(x), method="complete")
x <- read.delim("clipboard")
x
x <- read.delim("clipboard")
x
names(x)
x <- read.delim("clipboard")
x
names(x)
hclust.complete <- hclust(dist(x), method="complete")
hclust.average <- hclust(dist(x), method="average")
hclust.single <- hclust(dist(x), method="single")
plot(hclust.complete)
plot(hclust.average)
plot(hclust.single)
plot(hclust.complete)
plot(hclust.average)
plot(hclust.single)
pokemon <- read.delim("clipboard")
head(pokemon)
colMeans(pokemon)
apply(pokemon, 2, sd)
pokemon.scaled <- scale(pokemon)
hclust.pokemon <- hclust(dist(pokemon.scaled), method="complete")
plot(hclust.pokemon)
data = iris[,-5]
head(data)
km <- kmeans(data, centers = 3)
km
library(cluster)
data(xclara)
head(xclara)
km <- kmeans(xclara,3)
km
km$cl
sk <- silhouette(km$cl, dissE)
dissE <- daisy(xclara)
sk <- silhouette(km$cl, dissE)
plot(sk)
window()
windows()
plot(sk)
head(xclara)
dissE <- daisy(xclara)
sk <- silhouette(km$cl, dissE)
windows()
plot(sk)
km
km[1]
km[2]
km
km[5]
url <- "http://s3.amazonaws.com/assets.datacamp.com/production/course_1903/datasets/WisconsinCancer.csv"
wisc.df <- read.csv(url)
wisc.data[1:6, 1:5]
wisc.df[1:6, 1:5]
url <- "http://s3.amazonaws.com/assets.datacamp.com/production/course_1903/datasets/WisconsinCancer.csv"
wisc.df <- read.csv(url)
wisc.data <- as.matrix(wisc.df)
row.names(wisc.data) <- wisc.df$id
diagnosis <- as.numeric(wisc.df$diagnosis == "M")
head(wisc.data)
wisc.data <- as.matrix(wisc.df[3:32])
row.names(wisc.data) <- wisc.df$id
diagnosis <- as.numeric(wisc.df$diagnosis == "M")
head(wisc.data)
head(wisc.df)
dim(wisc.data)
colnames(wisc.data)
table(diagnosis)
grep("_mean", colnames(wisc.data))
length(grep("_mean", colnames(wisc.data)))
colnames(wisc.data)[(grep("_mean", colnames(wisc.data)))]
ls()
colMeans(wisc.data)
apply(wisc.data, 2, sd)
wisc.pr <- prcomp(wisc.data, scale=TRUE)
summary(wisc.pr)
biplot(wisc.pr)
plot(wisc.pr$rotation[, c(1, 2)], col = (diagnosis + 1),
xlab = "PC1", ylab = "PC2")
plot(wisc.pr$rotation[, c(1, 3)], col = (diagnosis + 1),
xlab = "PC1", ylab = "PC3")
plot(wisc.pr$rotation[, c(1, 4)], col = (diagnosis + 1),
xlab = "PC1", ylab = "PC4")
biplot(wisc.pr)
plot(wisc.pr$x[, c(1, 2)], col = (diagnosis + 1),
xlab = "PC1", ylab = "PC2")
plot(wisc.pr$x[, c(1, 3)], col = (diagnosis + 1),
xlab = "PC1", ylab = "PC3")
plot(wisc.pr$x[, c(1, 4)], col = (diagnosis + 1),
xlab = "PC1", ylab = "PC3")
plot(wisc.pr$x[, c(1, 2)], col = (diagnosis + 1),
xlab = "PC1", ylab = "PC2")
plot(wisc.pr$x[, c(1, 3)], col = (diagnosis + 1),
xlab = "PC1", ylab = "PC3")
par(mfrow = c(1, 2))
pr.var <- wisc.pr$sdev^2
pve <- pr.var/sum(pr.var)
plot(pve, xlab = "Principal Component",
ylab = "Proportion of Variance Explained",
ylim = c(0, 1), type = "b")
plot(cumsum(pve), xlab = "Principal Component",
ylab = "Cummulative Proportion of Variance Explained",
ylim = c(0, 1), type = "b")
wise.pr$rotation
wisc.pr$rotation[rownames(wisc.pr$rotation)=="concave.points_mean",]
wisc.pr$rotation[rownames(wisc.pr$rotation)=="concave.points_mean",][1]
round(colMeans(wisc.data),1)
round(apply(wisc.data,2,sd),1)
data.scaled <- scale(wisc.data)
data.dist <- dist(data.scaled)
wisc.hclust <- hclust(data.dist, method="complete")
round(colMeans(data.scaled),1)
round(apply(data.scaled,2,sd),1)
plot(wisc.hclust)
plot(wisc.hclust)
wisc.hclust.clusters <- cutree(wisc.hclust, k=4)
table(wisc.hclust.clusters, diagnosis)
wisc.km <- kmeans(scale(wisc.data), centers=2, nstart=20)
table(wisc.km$cluster, diagnosis)
table(wisc.km$cluster, wisc.hclust.clusters)
pve <- pr.var/sum(pr.var)
plot(cumsum(pve), xlab = "Principal Component",
ylab = "Cummulative Proportion of Variance Explained",
ylim = c(0, 1), type = "b")
summary(wisc.pr)
class(summary(wisc.pr))
pve
len(pve)
length(pve)
for(i in 1:length(pve)){
paste("Num of Components", i, "Variance", cumsum(pve[1:i]))
}
print(paste("Num of Components", i, "Variance", cumsum(pve[1:i])))
for(i in 1:length(pve)){
print(paste("Num of Components", i, "Variance", round(cumsum(pve[1:i]),1)))
}
for(i in 1:length(pve)){
print(paste("Num of Components", i, "Variance", round(cumsum(pve[1:i]))))
}
for(i in 1:length(pve)){
print(paste("Num of Components", i, "Variance", cumsum(pve[1:i])))
}
head(mtcars)
colMeans(mtcars)
data.frame(colMeans(mtcars))
apply(mtcars, 2, sd)
data.frame(apply(mtcars, 2, sd))
mtcars_scaled <- scale(mtcars)
head(mtcars_scaled)
data.frame(colMeans(mtcars_scaled))
data.frame(apply(mtcars_scaled, 2, sd))
center(mtcars)
?scale
new_text <- "DataCamp is the first online learning platform that focuses on building the best learning experience specifically for Data Science. We have offices in Boston and Belgium and to date, we trained over 250,000 (aspiring) data scientists in over 150 countries. These data science enthusiasts completed more than 9 million exercises. You can take free beginner courses, or subscribe for $25/month to get access to all premium courses."
library(qdap)
install.packages("qdap")
library(qdap)
library(qdap)
install.packages("qdapRegex")
library(qdapRegex)
library(qdap)
install.packages("‘qdapTools’")
library(qdapRegex)
library(qdap)
library(qdapTool)
library(qdapTools)
install.packages("qdapTools")
library(qdapRegex)
library(qdapTools)
library(qdap)
install.packages("qdap")
library(gender)
library(qdap)
print(new_text)
term_count <- freq_terms(new_text,10)
plot(term_count)
?kmeans
?hclust
?pam
setwd("~/GitHub/Python/Machine Learning A-Z Template Folder/Part 5 - Association Rule Learning/Section 28 - Apriori/Apriori")
dataset = read.transactions('Market_Basket_Optimisation.csv', sep = ',', rm.duplicates = TRUE)
library(arules)
dataset = read.csv('Market_Basket_Optimisation.csv', header = FALSE)
View(dataset)
dataset = read.transactions('Market_Basket_Optimisation.csv', sep = ',', rm.duplicates = TRUE)
summary(dataset)
str(dataset)
dataset$data
inspect(dataset)
head(inspect(dataset))
head(dataset)
inspect(head(dataset))
itemFrequencyPlot(dataset, topN = 10)
dataset$content
library(readxl)
sales <- read_excel("DAILY_SALE RETAIL_540_2013.xls", sheet=1)
dim(sales)
names(sales)
sales <- read_excel("DAILY_SALE RETAIL_540_2013.xls", sheet=2)
dim(sales)
names(sales)
?read_excel
sales <- read_excel("DAILY_SALE RETAIL_540_2013.xls", sheet="Sheet2")
View(sales)
dim(sales)
names(sales)
library(dplyr)
s <- select(sales, INV_NO,ITEM_CODE)
dim(s)
head(s)
dim(sales)
head(sales)
dim(s)
unique(s$INV_NO)
head(s)
head(arrange(s, INV_NO,ITEM_CODE))
head(s,10)
s <- (arrange(s, INV_NO,ITEM_CODE))
head(s,10)
head(s,20)
unique(s$ITEM_CODE)
length(unique(s$ITEM_CODE))
length(unique(s$INV_NO))
head(s,20)
length(unique(s$ITEM_CODE))
dim(s)
s <- head(s,300)
head(s,20)
length(unique(s$INV_NO))
s %>% group_by(INV_NO) %>% paste(collapse=",")
g<-group_by(s, INV_NO)
h <- paste(g$ITEM_CODE, collapse = ",")
h
len(h)
length(h)
u <- unique(g$ITEM_CODE)
u
apply(g$ITEM_CODE, u, function(x){paste(x, collapse = ",")})
tapply(g$ITEM_CODE, u, function(x){paste(x, collapse = ",")})
head(g)
tapply(g$ITEM_CODE, g$INV_NO, function(df1)paste(df1$itemDescription,collapse = ","))
tapply(g$ITEM_CODE, g$INV_NO, function(df1)paste(df1,collapse = ","))
t<-tapply(g$ITEM_CODE, g$INV_NO, function(df1)paste(df1,collapse = ","))
class(t)
t[1:5]
td <- data.frame(t)
head(td)
class(td)
tail(td)
dim(td)
names(td)<- "desc"
final <- separate(td, desc, c("invoice", "itmes"), sep=" ")
library(tidyr)
final <- separate(td, desc, c("invoice", "itmes"), sep=" ")
head(final)
grocery <- read.csv("Groceries_dataset.csv")
head(grocery)
td <- s %>% group_by(c("Member_number","Date"))
td <- grocery %>% group_by(c("Member_number","Date"))
t<-tapply(grocery$itemDescription, grocery$Member_number, function(df1)paste(df1,collapse = ","))
t
class(t
)
f <- data.frame(t)
head(f)
head(f)
dim(f)
head(grocey)
head(grocery)
arrange(grocery, Member_number, Date)
group_by(grocery, c("Member_number", "Date"))
names(grocery)
group_by(grocery, Member_number, Date)
?summarize
head(Groceries)
data(Groceries)
head(Groceries)
inspect(Groceries)
class(Groceries)
